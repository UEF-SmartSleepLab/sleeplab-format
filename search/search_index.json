{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sleeplab-format v0.3.0","text":"<p>A standardized format for polysomnography recordings.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sleeplab-format\n</code></pre>"},{"location":"#basic-example","title":"Basic example","text":"<pre><code>import sleeplab_format as slf\nfrom pathlib import Path\n\nDS_DIR = Path('/path/to/dataset')\nds = slf.reader.read_dataset(DATASET_DIR)\n\n# TODO: Example of how to access data\n\n# ...Do some processing and modify the dataset\n\nMODIFIED_DS_DIR = Path('/path/to/modified_dataset')\nslf.writer.write_dataset(ds, MODIFIED_DATASET_DIR)\n</code></pre> <p>See usage and examples for more detailed information.</p>"},{"location":"#related-tools","title":"Related tools","text":"<p>sleeplab-converters for converting other formats exported from PSG software to sleeplab format.</p> <p>sleeplab-extractor for extracting and preprocessing a subset of data in sleeplab format for the needs of specific studies.</p> <p>sleeplab-tf-dataset for reading data in sleeplab format as a tensorflow Dataset.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We follow Github flow in the development. </p> <p>The basic procedure to contribute code to the project is:</p> <ol> <li>Install from cloned repository</li> <li>Create your own branch and implement the changes (and tests, preferably)</li> <li>Make sure the tests pass</li> <li>Create a pull request on Github</li> <li>Another contributor reviews the pull request</li> <li>Fix review comments if any</li> <li>Reviewer merges the pull request</li> </ol>"},{"location":"contributing/#install-from-cloned-repository","title":"Install from cloned repository","text":"<p>Clone repository to your local files: <pre><code>git clone git@github.com:UEF-SmartSleepLab/sleeplab-format.git\n</code></pre></p> <p>This project uses Hatch for project management. First, install hatch. You will also need a recent version of pip.</p> <p>Then, go to the root of the cloned repository and create an environment for it: <pre><code>hatch env create\n</code></pre></p> <p>After that, you can enter the environment by: <pre><code>hatch shell\n</code></pre></p> <p>You can confirm that the project has been installed by: <pre><code>pip show sleeplab-format\n</code></pre></p>"},{"location":"contributing/#running-tests","title":"Running tests","text":"<p>This project uses <code>pytest</code> for testing. To run the tests after cloning and installing, go to the root of the cloned repository and run: <pre><code>pytest\n</code></pre></p>"},{"location":"contributing/#documenting-the-source-code","title":"Documenting the source code","text":"<p>The source code should be documented using Google style docstrings.</p>"},{"location":"contributing/#generating-the-documentation","title":"Generating the documentation","text":"<p>This documentation is created using Material for MkDocs and mkdocstrings. The documentation is published using Github Pages. There are utility scripts defined in <code>pyproject.toml</code> to build and publish the documentation.</p> <p>When working on documentation, use hatch environment <code>docs</code>: <pre><code>hatch -e docs shell\n</code></pre></p> <p>Build the documentation: <pre><code>hatch run docs:build\n</code></pre></p> <p>Serve the documentation on local machine for inspection: <pre><code>hatch run docs:serve\n</code></pre></p> <p>Publish the documentation: <pre><code>hatch run docs:publish\n</code></pre></p>"},{"location":"usage/","title":"Concepts and usage","text":"<p>TODO</p>"},{"location":"api/models/","title":"Models","text":"<p>Data type definitions for the sleeplab format.</p>"},{"location":"api/models/#sleeplab_format.models.Dataset","title":"<code>Dataset</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Dataset(BaseModel, extra='forbid'):\n    name: str\n    version: str = SLEEPLAB_FORMAT_VERSION\n    series: Optional[dict[str, Series]] = None\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Series","title":"<code>Series</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Series(BaseModel, extra='forbid'):\n    name: str\n    subjects: dict[str, Subject] = Field(repr=False)\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Subject","title":"<code>Subject</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Subject(BaseModel, extra='forbid'):\n    metadata: SubjectMetadata\n    sample_arrays: Optional[dict[str, SampleArray]] = Field(None, repr=False)\n    annotations: Optional[dict[str, BaseAnnotations]] = Field(None, repr=False)\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SubjectMetadata","title":"<code>SubjectMetadata</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class SubjectMetadata(BaseModel, extra='forbid'):\n    subject_id: str\n\n    # Recording start time\n    recording_start_ts: NaiveDatetime\n\n    lights_off: Optional[NaiveDatetime] = None\n    lights_on: Optional[NaiveDatetime] = None\n    analysis_start: Optional[NaiveDatetime] = None\n    analysis_end: Optional[NaiveDatetime] = None\n\n    age: Optional[float] = None\n    bmi: Optional[float] = None\n    sex: Optional[Sex] = None\n\n    additional_info: Optional[dict[str, Any]] = None\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SampleArray","title":"<code>SampleArray</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A pydantic model representing a numerical array with attributes.</p> <p>When writing data to sleeplab format, use <code>values_func</code> to access the array to avoid caching.</p> <p>When reading data in sleeplab format, use <code>values</code> since the <code>values_func</code> returned by the reader should return <code>np.memmap</code> instead of the full array.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class SampleArray(\n        BaseModel,\n        extra='forbid',\n        ignored_types=(cached_property,)):\n    \"\"\"A pydantic model representing a numerical array with attributes.\n\n    When writing data to sleeplab format, use `values_func` to access the array\n    to avoid caching.\n\n    When reading data in sleeplab format, use `values` since the `values_func`\n    returned by the reader should return `np.memmap` instead of the full array.\n    \"\"\"\n    attributes: ArrayAttributes\n    values_func: Callable[[], np.ndarray]\n\n    @cached_property\n    def values(self) -&gt; np.ndarray:\n        \"\"\"Use @cached_property so that values_func gets evaluated once\n        when values is accessed first time.\n        \"\"\"\n        return self.values_func()\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SampleArray.values","title":"<code>values: np.ndarray</code>  <code>cached</code> <code>property</code>","text":"<p>Use @cached_property so that values_func gets evaluated once when values is accessed first time.</p>"},{"location":"api/models/#sleeplab_format.models.ArrayAttributes","title":"<code>ArrayAttributes</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class ArrayAttributes(BaseModel, extra='forbid'):\n    name: str\n    start_ts: NaiveDatetime\n    sampling_rate: Optional[float] = None\n    sampling_interval: Optional[float] = None\n    unit: Optional[str] = None\n\n    amplifier_info: Optional[str] = None\n    sensor_info: Optional[str] = None\n\n    # An optional mapping from the array values to some other values,\n    # e.g.  {0: 'off', 1: 'on'}\n    value_map: Optional[dict[int, str | int]] = None\n\n    @model_validator(mode='after')\n    def require_rate_or_interval(self):\n        if self.sampling_interval is None:\n            _msg = 'either sampling_rate or sampling_interval needs to be defined'\n            assert self.sampling_rate is not None, _msg\n        else:\n            _msg = 'cannot define both sampling_rate and sampling_interval'\n            assert self.sampling_rate is None, _msg\n\n        return self\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.BaseAnnotations","title":"<code>BaseAnnotations</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class BaseAnnotations(BaseModel):\n    scorer: str\n    type: str\n    annotations: list[Annotation]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Annotations","title":"<code>Annotations</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Annotations(BaseAnnotations):\n    type: Literal['annotations'] = 'annotations'\n    annotations: list[Annotation[str]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMEvents","title":"<code>AASMEvents</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMEvents(BaseAnnotations):\n    type: Literal['aasmevents'] = 'aasmevents'\n    annotations: list[Annotation[AASMEvent]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Hypnogram","title":"<code>Hypnogram</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> <p>A hypnogram is Annotations consisting of sleep stages.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Hypnogram(BaseAnnotations):\n    \"\"\"A hypnogram is Annotations consisting of sleep stages.\"\"\"\n    type: Literal['hypnogram'] = 'hypnogram'\n    annotations: list[Annotation[AASMSleepStage]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Sex","title":"<code>Sex</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Sex(str, Enum):\n    FEMALE = 'FEMALE'\n    MALE = 'MALE'\n    OTHER = 'OTHER'\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMEvent","title":"<code>AASMEvent</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for events scored according to the AASM manual v2.6.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMEvent(str, Enum):\n    \"\"\"Enum for events scored according to the AASM manual v2.6.\"\"\"\n    # A generic class for artifacts\n    ARTIFACT = 'ARTIFACT'\n\n    # A generic class for unsure\n    UNSURE = 'UNSURE'\n\n    # Arousal events\n    AROUSAL = 'AROUSAL'\n    AROUSAL_RES = 'AROUSAL_RES'\n    AROUSAL_SPONT = 'AROUSAL_SPONT'\n    AROUSAL_LM = 'AROUSAL_LM'\n    AROUSAL_PLM = 'AROUSAL_PLM'\n    RERA = 'RERA'\n\n    # Cardiac events\n    # TODO: Add these if a use case ever pops up\n\n    # Movement events\n    BRUXISM = 'BRUXISM'\n    LM = 'LM'  # Leg movement\n    LM_LEFT = 'LM_LEFT',\n    LM_RIGHT = 'LM_RIGHT',\n    PLM = 'PLM'  # Periodic leg movement\n    PLM_LEFT = 'PLM_LEFT'\n    PLM_RIGHT = 'PLM_RIGHT'\n\n    # Respiratory events\n    APNEA = 'APNEA'\n    APNEA_CENTRAL = 'APNEA_CENTRAL'\n    APNEA_OBSTRUCTIVE = 'APNEA_OBSTRUCTIVE'\n    APNEA_MIXED = 'APNEA_MIXED'\n    HYPOPNEA = 'HYPOPNEA'\n    HYPOPNEA_CENTRAL = 'HYPOPNEA_CENTRAL'\n    HYPOPNEA_OBSTRUCTIVE = 'HYPOPNEA_OBSTRUCTIVE'\n    SPO2_DESAT = 'SPO2_DESAT'\n    SNORE = 'SNORE'\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMSleepStage","title":"<code>AASMSleepStage</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Sleep stages according to the AASM manual v2.6.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMSleepStage(str, Enum):\n    \"\"\"Sleep stages according to the AASM manual v2.6.\"\"\"\n    W = 'W'\n    N1 = 'N1'\n    N2 = 'N2'\n    N3 = 'N3'\n    R = 'R'\n\n    # These are not part of the AASM v2.6 definition, but still commonly used\n    UNSURE = 'UNSURE'\n    UNSCORED = 'UNSCORED'\n    ARTIFACT = 'ARTIFACT'\n</code></pre>"},{"location":"api/reader/","title":"Reader","text":"<p>Read files into sleeplab format. The data will be validated while parsing.</p>"},{"location":"api/reader/#sleeplab_format.reader.read_dataset","title":"<code>read_dataset(ds_dir, series_names=None, include_annotations=True)</code>","text":"<p>Read a dataset stored in sleeplab-format.</p> <p>Parameters:</p> Name Type Description Default <code>ds_dir</code> <code>Path</code> <p>The dataset root folder.</p> required <code>series_names</code> <code>list[str] | None</code> <p>The series included in the resulting dataset.</p> <code>None</code> <code>include_annotations</code> <code>bool</code> <p>Whether to include annotations or only read the sample arrays.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The resulting dataset.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_dataset(\n        ds_dir: Path,\n        series_names: list[str] | None = None,\n        include_annotations: bool = True) -&gt; Dataset:\n    \"\"\"Read a dataset stored in sleeplab-format.\n\n    Arguments:\n        ds_dir: The dataset root folder.\n        series_names: The series included in the resulting dataset.\n        include_annotations: Whether to include annotations or only read the sample arrays.\n\n    Returns:\n        The resulting dataset.\n    \"\"\"\n    with open(ds_dir / 'metadata.json', 'r') as f:\n        ds_meta = json.load(f)\n\n    assert ds_meta['name'] == ds_dir.name\n    if ds_meta['version'] != SLEEPLAB_FORMAT_VERSION:\n        logger.warning(\n            f'Reading dataset version {ds_meta[\"version\"]} with sleeplab-format version {SLEEPLAB_FORMAT_VERSION}')\n\n    if series_names is None:\n        series = {series_dir.name: read_series(\n                series_dir, include_annotations=include_annotations)\n            for series_dir in ds_dir.iterdir()\n            if series_dir.is_dir() and not series_dir.name.startswith('.')}  # Ignore hidden folders.\n    else:\n        series = {series_name: read_series(\n                ds_dir / series_name, include_annotations=include_annotations)\n            for series_name in series_names}\n\n    return Dataset(\n        series=series,\n        **ds_meta\n    )\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_series","title":"<code>read_series(series_dir, include_annotations=True)</code>","text":"<p>Read a single series to <code>sleeplab_format.models.Series</code>.</p> <p>Parameters:</p> Name Type Description Default <code>series_dir</code> <code>Path</code> <p>The series root folder.</p> required <code>include_annotations</code> <code>bool</code> <p>Whether to include the annotations.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series</code> <p>The resulting series.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_series(\n        series_dir: Path,\n        include_annotations: bool = True) -&gt; Series:\n    \"\"\"Read a single series to `sleeplab_format.models.Series`.\n\n    Arguments:\n        series_dir: The series root folder.\n        include_annotations: Whether to include the annotations.\n\n    Returns:\n        The resulting series.\n    \"\"\"\n    return Series(\n        name=series_dir.name,\n        subjects={subject_dir.name: read_subject(\n                subject_dir, include_annotations=include_annotations)\n            for subject_dir in series_dir.iterdir()\n            if not subject_dir.name.startswith('.')}  # Ignore hidden folders.\n    )\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_annotations","title":"<code>read_annotations(subject_dir)</code>","text":"<p>Read all subject's annotations.</p> <p>Parameters:</p> Name Type Description Default <code>subject_dir</code> <code>Path</code> <p>The subject folder.</p> required <p>Returns:</p> Type Description <code>dict[str, list[Annotation]] | None</code> <p>All annotations in a dictionary.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_annotations(subject_dir: Path) -&gt; dict[str, list[Annotation]] | None:\n    \"\"\"Read all subject's annotations.\n\n    Arguments:\n        subject_dir: The subject folder.\n\n    Returns:\n        All annotations in a dictionary.\n    \"\"\"\n    annotations = {}\n    for p in subject_dir.iterdir():\n\n        if p.name.endswith(JSON_ANNOTATION_SUFFIX):            \n            annotation_name = p.name.removesuffix(JSON_ANNOTATION_SUFFIX)\n            with open(p, 'rb') as f:\n                raw_data = f.read()\n                annotations[annotation_name] = BaseAnnotations.model_validate_json(raw_data)\n        elif p.name.endswith(PARQUET_ANNOTATION_SUFFIX):\n            annotation_name = p.name.removesuffix(PARQUET_ANNOTATION_SUFFIX)\n            annotation_meta_path = subject_dir / f'{annotation_name}{PARQUET_ANNOTATION_META_SUFFIX}'\n\n            with open(annotation_meta_path, 'r') as f:\n                ann_dict = json.load(f)\n\n            ann_df = pd.read_parquet(p)\n            ann_dict['annotations'] = ann_df.to_dict('records')\n\n            annotations[annotation_name] = BaseAnnotations.model_validate(ann_dict)\n\n    if len(annotations) == 0:\n        return None\n    return annotations\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_sample_arrays","title":"<code>read_sample_arrays(subject_dir)</code>","text":"<p>Read all subject's sample arrays.</p> <p>Parameters:</p> Name Type Description Default <code>subject_dir</code> <code>Path</code> <p>The subject folder.</p> required <p>Returns:</p> Type Description <code>dict[str, SampleArray] | None</code> <p>All sample arrays in a dictionary.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_sample_arrays(subject_dir: Path) -&gt; dict[str, SampleArray] | None:\n    \"\"\"Read all subject's sample arrays.\n\n    Arguments:\n        subject_dir: The subject folder.\n\n    Returns:\n        All sample arrays in a dictionary.\n    \"\"\"\n    sarrs = {}\n    for p in subject_dir.iterdir():\n        if p.is_dir() and not p.name.startswith('.'):\n            with open(p / 'attributes.json', 'rb') as f:\n                raw_data = f.read()\n                attributes = ArrayAttributes.model_validate_json(raw_data)\n\n            if (p / 'data.npy').exists():\n                # Return a function that returns a memmapped numpy array\n                values_func = lambda _p=p / 'data.npy': np.load(\n                    _p, mmap_mode='r', allow_pickle=False)\n            elif (p / 'data.parquet').exists():\n                values_func = lambda _p=p / 'data.parquet': pq.read_table(\n                    _p)['data'].to_numpy()\n            else:\n                raise FileNotFoundError(f'No data.npy or data.parquet in {p}')\n\n            assert p.name == attributes.name\n            sarrs[p.name] = SampleArray(\n                attributes=attributes, values_func=values_func)\n    return sarrs\n</code></pre>"},{"location":"api/writer/","title":"Writer","text":"<p>Write validated data into sleeplab format.</p> <p>The data needs to conform to the types specified in <code>sleeplab_format.models</code>.</p>"},{"location":"api/writer/#sleeplab_format.writer.write_dataset","title":"<code>write_dataset(dataset, basedir, annotation_format='json', array_format='numpy')</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_dataset(\n        dataset: Dataset,\n        basedir: str,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy') -&gt; None:\n    assert annotation_format in ['json', 'parquet']\n    assert array_format in ['numpy', 'parquet']\n\n    # Create the folder\n    dataset_path = Path(basedir) / dataset.name\n    logger.info(f'Creating dataset dir {dataset_path}...')\n    dataset_path.mkdir(parents=True, exist_ok=True)\n\n    # Write the dataset metadata\n    metadata_path = dataset_path / 'metadata.json'\n    metadata_path.write_text(\n        dataset.model_dump_json(exclude={'series'}, indent=JSON_INDENT))\n\n    # Write the series\n    for name, series in dataset.series.items():\n        assert name == series.name\n        logger.info(f'Writing data for series {series.name}...')\n        series_path = dataset_path / series.name\n        series_path.mkdir(exist_ok=True)\n\n        write_series(\n            series,\n            series_path,\n            annotation_format=annotation_format,\n            array_format=array_format)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_series","title":"<code>write_series(series, series_path, annotation_format='json', array_format='numpy')</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_series(\n        series: Series,\n        series_path: Path,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy') -&gt; None:\n    for sid, subject in series.subjects.items():\n        logger.info(f'Writing subject ID {sid}...')\n        subject_path = series_path / subject.metadata.subject_id\n        write_subject(\n            subject,\n            subject_path,\n            annotation_format=annotation_format,\n            array_format=array_format)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_subject","title":"<code>write_subject(subject, subject_path, annotation_format='json', array_format='numpy')</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_subject(\n        subject: Subject,\n        subject_path: Path,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy') -&gt; None:\n    subject_path.mkdir(exist_ok=True)\n    write_subject_metadata(subject, subject_path)\n\n    write_sample_arrays(subject, subject_path, format=array_format)\n\n    if subject.annotations is not None:\n        write_annotations(subject, subject_path, format=annotation_format)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_annotations","title":"<code>write_annotations(subject, subject_path, format='json')</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_annotations(\n        subject: Subject,\n        subject_path: Path,\n        format: str = 'json') -&gt; None:\n    for k, v in subject.annotations.items():\n        _msg = f'Annotation key should equal to \"{v.scorer}_{v.type}\", got \"{k}\"'\n        assert k == f'{v.scorer}_{v.type}', _msg\n\n        if format == 'json':\n            json_path = subject_path / f'{k}{JSON_ANNOTATION_SUFFIX}'\n            json_path.write_text(\n                v.model_dump_json(exclude_none=True, indent=JSON_INDENT)\n            )\n        else:\n            # Write the actual annotations in parquet, metadata in json\n            metadata_path = subject_path / f'{k}{PARQUET_ANNOTATION_META_SUFFIX}'\n            pq_path = subject_path / f'{k}{PARQUET_ANNOTATION_SUFFIX}'\n\n            ann_dict = v.model_dump()\n            ann_list = ann_dict.pop('annotations')\n\n            with open(metadata_path, 'w') as f:\n                json.dump(ann_dict, f)\n\n            pd.DataFrame(ann_list).to_parquet(pq_path)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_sample_arrays","title":"<code>write_sample_arrays(subject, subject_path, format='numpy')</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_sample_arrays(\n        subject: Subject,\n        subject_path: Path,\n        format: str = 'numpy') -&gt; None:\n    for name, sarr in subject.sample_arrays.items():\n        assert name == sarr.attributes.name\n        sarr_path = subject_path / f'{sarr.attributes.name}'\n        sarr_path.mkdir(exist_ok=True)\n\n        # Write the attributes\n        attr_path = sarr_path / 'attributes.json'\n        attr_path.write_text(\n            sarr.attributes.model_dump_json(indent=JSON_INDENT, exclude_none=True))\n\n        arr = sarr.values_func()\n        if format == 'numpy':\n            # Write the array\n            arr_fname = 'data.npy'\n            np.save(sarr_path / arr_fname, arr, allow_pickle=False)\n        elif format == 'parquet':\n            arr_fname = 'data.parquet'\n\n            # Utilize Arrow to write the data to Parquet file\n            arrow_table = pa.Table.from_arrays([arr], names=['data'])\n\n            # Parquet uses Snappy as compression algorithm by default\n            pq.write_table(arrow_table, sarr_path / arr_fname)\n        else:\n            raise AttributeError(f'Unsupported sample array format: {format}')\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_subject_metadata","title":"<code>write_subject_metadata(subject, subject_path)</code>","text":"Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_subject_metadata(\n        subject: Subject,\n        subject_path: Path) -&gt; None:\n    metadata_path = subject_path / 'metadata.json'\n    metadata_path.write_text(\n        subject.metadata.model_dump_json(indent=JSON_INDENT, exclude_none=True),\n    )\n</code></pre>"},{"location":"examples/automatic_sleep_staging/","title":"Sleep staging using Dreem Open Datasets","text":"<p>This is an end-to-end example of how to convert data from another format to sleeplab format, how to preprocess the data using sleeplab-extractor, and how to train a deep learning model utilizing sleeplab-tf-dataset. The code is available on Github. This example uses data from Dreem Open Datasets (DOD) since the DOD is well documented and open access (https://doi.org/10.1109/TNSRE.2020.3011181).</p>"},{"location":"examples/automatic_sleep_staging/#prerequisites","title":"Prerequisites","text":"<p>The code is developed and tested with Linux and Python 3.10. Windows users can install Windows Subsystem for Linux to run this example (and to use Linux for development in general).</p> <p>If you do not yet have a copy of this example, you can clone the repository to current working directory and go to the example folder: <pre><code>git clone https://github.com/UEF-SmartSleepLab/sleeplab-format.git\ncd sleeplab-format/examples/dod_sleep_staging\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#install-dependencies","title":"Install dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"examples/automatic_sleep_staging/#convert-data-to-sleeplab-format","title":"Convert data to sleeplab format","text":"<p>NOTE: This will download and convert the whole dataset with the original 250Hz sampling rate. The h5 files take 57 GB on disk, and the converted slf dataset takes 30 GB.</p> <p>The examples below use <code>/tmp</code> as the base directory. Substitute it with another location if you want to persist the data and results.</p> <p>First, download the datasets <pre><code>mkdir /tmp/dod\npython download_data.py --dst-dir /tmp/dod\n</code></pre></p> <p>Then, run the conversion <pre><code>python convert_data.py --src-dir /tmp/dod --dst-dir /tmp/slf\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#extract-and-preprocess-a-subset-of-the-signals","title":"Extract and preprocess a subset of the signals","text":"<p>Use sleeplab-extractor to extract a single EEG channel, EOG channel, and EMG channel. Resample to 64Hz, highpass filter, and normalize the signals.</p> <p>All configurations for the extractor are in <code>sleeplab_extractor_config.yml</code>.</p> <p>To perform the extraction, run in this directory: <pre><code>sleeplab-extract --src_dir /tmp/slf/dod --dst_dir /tmp/slf --config_path ./sleeplab_extractor_config.yml\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#train-a-sleep-staging-model-with-the-data","title":"Train a sleep staging model with the data","text":"<p>Now, use the preprocessed 64Hz data for automatic sleep staging. The model and training loop are defined in <code>train.py</code>.</p> <pre><code>python train.py --model-dir /tmp/dod_models --epochs 100\n</code></pre> <p>This should achieve 75-85% validation accuracy, and 70-80% test accuracy. Since the dataset is relatively small (50, 11, and 20 recordings for training, validation, and test sets), the performance fluctuates quite much between the runs. No hyperparameter tuning has been performed, default values are used everywhere.</p>"},{"location":"examples/edf_conversion/","title":"Converting the Sleep Cassette dataset to sleeplab-format","text":"<p>This is an example of how to convert EDF and EDF+ files to sleeplab-format. The example uses the Sleep Cassette dataset, which is openly available for download and usage.</p>"},{"location":"examples/edf_conversion/#setup","title":"Setup","text":"<p>Clone the sleeplab-format repo and <code>cd</code> to the example folder. <pre><code>git clone https://github.com/UEF-SmartSleepLab/sleeplab-format.git\ncd examples/sleep_edf_conversion\n</code></pre></p> <p>Create environment with Python 3.10, for example with conda: <pre><code>conda create -n sleep_edf_conversion python=3.10\nconda activate sleep_edf_conversion\n</code></pre></p> <p>Install requirements <pre><code>pip install -r requirements.txt\n</code></pre></p>"},{"location":"examples/edf_conversion/#download-the-data","title":"Download the data","text":"<pre><code>wget -r -N -c -np https://physionet.org/files/sleep-edfx/1.0.0/\n</code></pre>"},{"location":"examples/edf_conversion/#convert-to-sleeplab-format","title":"Convert to sleeplab-format","text":"<p>The code for conversion is in <code>convert_data.py</code>. The module provides a command line interface, which takes as arguments: - --src-dir: The folder containing the original EDF data (<code>SC-subjects.xls</code> Excel and <code>sleep-cassette/</code> folder). - --dst-dir: The folder where the sleeplab-format dataset will be saved. - --array-format: The save format of the signals; <code>numpy</code> or <code>parquet</code>. - --annotation-format: The save format of the annotation files; <code>json</code> or <code>parquet</code>.</p> <p>For example, to store the signals as parquet files, and annotations as json files: <pre><code>python convert_data.py --src-dir physionet.org/files/sleep-edfx/1.0.0 \\\n    --dst-dir /tmp/sleeplab_format --array-format parquet --annotation-format json\n</code></pre></p> <p>The Sleep-Cassette dataset contains 153 PSG recordings, 20h duration each. There are two recordings recorded on consecutive dates for each subject. Detailed information can be found on the dataset documentation. The consecutive recordings are stored in separate sleeplab-format series <code>sc-night1</code> and <code>sc-night2</code>. Detailed information on the sleeplab-format data structures can be found in the sleeplab-format documentation.</p>"},{"location":"examples/edf_conversion/#resulting-dataset-sizes","title":"Resulting dataset sizes","text":"Dataset Size (Gb) Original EDF files 7.42 SLF, array format <code>numpy</code> 14.85 SLF, array format <code>parquet</code> 5.36 <p>The EDF files stores signals as 16-bit signed ints. In this example, the signals are stored as 32-bit floats in the sleeplab-format, which doubles the dataset size if uncompressed numpy files are used for the signals. However, if the signals are saved in parquet files, the size is reduced significantly from the original EDF files. The reason for this size reduction is currently not known. Parquet uses Snappy compression algorithm, which encodes recurring patterns as (pattern, count) pairs. However, EEG, EOG, and EMG signals are characterized by random fluctuations and noise, which means that a lossless compression algorithm should not be able to compress the data significantly. The size reduction might be related to the AD and EDF conversions, signal filtering, and artefacts.</p>"}]}