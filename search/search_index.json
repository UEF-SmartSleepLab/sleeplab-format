{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sleeplab-format v0.3.0","text":"<p>Sleeplab format (SLF) is a both machine and human-readable format to store and process polysomnography recordings. It provides reader and writer with built-in validation of the data types and structures. SLF was designed for harmonization of datasets from different sources to enable easier application of analysis and machine learning pipelines on multiple datasets.</p> <p>See Concepts for detailed description of the format.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sleeplab-format\n</code></pre>"},{"location":"#basic-example","title":"Basic example","text":"<p>Read, analyse, modify, and write SLF datasets.</p> <pre><code>import sleeplab_format as slf\nimport pandas as pd\nfrom pathlib import Path\n\n# Read a toy dataset\nDS_DIR = Path('tests/datasets/dataset1')\nds = slf.reader.read_dataset(DS_DIR)\n\n# Get the list of subjects from series1\nsubjects = ds.series['series1'].subjects.values()\n\n# Flatten the nested annotations and cast Pydantic models to dicts\nall_events_dict = [dict(a)\n    for s in subjects\n    for a_model in s.annotations.values()\n    for a in a_model.annotations\n]\n\n# Create a pandas DataFrame for analyses\nevent_df = pd.DataFrame(all_events_dict)\n\n# Calculate the mean duration of hypopneas\nhypopneas = event_df[event_df['name'] == 'HYPOPNEA']\nmean_duration = sum(hypopneas['duration']) / len(hypopneas)\n\n# Modify the dataset\nadditional_info = {'neck_size': 40.0}\nds.series['series1'].subjects['10001'].metadata.additional_info = additional_info\nds.name = 'dataset2'\n\n# Write the modified dataset\nMODIFIED_DS_DIR = Path('/tmp/datasets')\nslf.writer.write_dataset(ds, MODIFIED_DS_DIR)\n</code></pre> <p>See Examples for end-to-end use cases.</p>"},{"location":"#related-tools","title":"Related tools","text":"<p>sleeplab-converters for converting other formats exported from PSG software to sleeplab format.</p> <p>sleeplab-extractor for extracting and preprocessing a subset of data in sleeplab format for the needs of specific studies.</p> <p>sleeplab-tf-dataset for reading data in sleeplab format as a tensorflow Dataset.</p>"},{"location":"concepts/","title":"Concepts","text":"<p> Fig. 1: Overview of the Sleeplab format ecosystem.</p> <p>A schematic diagram of the Sleeplab format (SLF) is shown in Fig. 1. The heterogeneous source data consists of the different file formats used with different PSG recording software. When a new dataset comes, the first task is to convert it to SLF. The converters contain the uggly part of wrangling the source data to SLF models. After that, the writer can be used to save the SLF dataset on disk. The SLF dataset can then be read to memory with the reader. Both reader and writer validate the data types and structures when they are used.</p> <p></p> <p>Fig. 2: Class diagram of the SLF base classes.</p> <p>SLF uses Pydantic models to represent the data. Pydantic models provides automatic validation of data types for Python classes. The compositon of models in SLF is shown in Fig. 2. A SLF dataset consists of any number of series, which can contain any number of subjects. Subjects consist of metadata, sample arrays, and annotations.</p> <p> Fig. 3: The SLF file format</p> <p>SLF utilizes the file system to represent the dataset hierarchy on disk (Fig. 3). Datasets are folders, series are folders, and subjects are folders. All metadata and annotations are stored in plain-text JSON files by default. The PSG signals are stored in their own folders. The actual signal is stored in a binary format (NumPy files by default), and all metadata related to the signal is stored  in a JSON file.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We follow Github flow in the development. </p> <p>The basic procedure to contribute code to the project is:</p> <ol> <li>Install from cloned repository</li> <li>Create your own branch and implement the changes (and tests, preferably)</li> <li>Make sure the tests pass</li> <li>Create a pull request on Github</li> <li>Another contributor reviews the pull request</li> <li>Fix review comments if any</li> <li>Reviewer merges the pull request</li> </ol>"},{"location":"contributing/#install-from-cloned-repository","title":"Install from cloned repository","text":"<p>Clone repository to your local files: <pre><code>git clone git@github.com:UEF-SmartSleepLab/sleeplab-format.git\n</code></pre></p> <p>This project uses Hatch for project management. First, install hatch. You will also need a recent version of pip.</p> <p>Then, go to the root of the cloned repository and create an environment for it: <pre><code>hatch env create\n</code></pre></p> <p>After that, you can enter the environment by: <pre><code>hatch shell\n</code></pre></p> <p>You can confirm that the project has been installed by: <pre><code>pip show sleeplab-format\n</code></pre></p>"},{"location":"contributing/#running-tests","title":"Running tests","text":"<p>This project uses <code>pytest</code> for testing. To run the tests after cloning and installing, go to the root of the cloned repository and run: <pre><code>pytest\n</code></pre></p>"},{"location":"contributing/#documenting-the-source-code","title":"Documenting the source code","text":"<p>The source code should be documented using Google style docstrings.</p>"},{"location":"contributing/#generating-the-documentation","title":"Generating the documentation","text":"<p>This documentation is created using Material for MkDocs and mkdocstrings. The documentation is published using Github Pages. There are utility scripts defined in <code>pyproject.toml</code> to build and publish the documentation.</p> <p>When working on documentation, use hatch environment <code>docs</code>: <pre><code>hatch -e docs shell\n</code></pre></p> <p>Build the documentation: <pre><code>hatch run docs:build\n</code></pre></p> <p>Serve the documentation on local machine for inspection: <pre><code>hatch run docs:serve\n</code></pre></p> <p>Publish the documentation: <pre><code>hatch run docs:publish\n</code></pre></p>"},{"location":"api/models/","title":"Models","text":"<p>Data type definitions for the sleeplab format.</p>"},{"location":"api/models/#sleeplab_format.models.Dataset","title":"<code>Dataset</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Dataset(BaseModel, extra='forbid'):\n    name: str\n    version: str = SLEEPLAB_FORMAT_VERSION\n    series: Optional[dict[str, Series]] = None\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Series","title":"<code>Series</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Series(BaseModel, extra='forbid'):\n    name: str\n    subjects: dict[str, Subject] = Field(repr=False)\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Subject","title":"<code>Subject</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Subject(BaseModel, extra='forbid'):\n    metadata: SubjectMetadata\n    sample_arrays: Optional[dict[str, SampleArray]] = Field(None, repr=False)\n    annotations: Optional[dict[str, BaseAnnotations]] = Field(None, repr=False)\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SubjectMetadata","title":"<code>SubjectMetadata</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class SubjectMetadata(BaseModel, extra='forbid'):\n    subject_id: str\n\n    # Recording start time\n    recording_start_ts: NaiveDatetime\n\n    lights_off: Optional[NaiveDatetime] = None\n    lights_on: Optional[NaiveDatetime] = None\n    analysis_start: Optional[NaiveDatetime] = None\n    analysis_end: Optional[NaiveDatetime] = None\n\n    age: Optional[float] = None\n    bmi: Optional[float] = None\n    sex: Optional[Sex] = None\n\n    additional_info: Optional[dict[str, Any]] = None\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SampleArray","title":"<code>SampleArray</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A pydantic model representing a numerical array with attributes.</p> <p>When writing data to sleeplab format, use <code>values_func</code> to access the array to avoid caching.</p> <p>When reading data in sleeplab format, use <code>values</code> since the <code>values_func</code> returned by the reader should return <code>np.memmap</code> instead of the full array.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class SampleArray(\n        BaseModel,\n        extra='forbid',\n        ignored_types=(cached_property,)):\n    \"\"\"A pydantic model representing a numerical array with attributes.\n\n    When writing data to sleeplab format, use `values_func` to access the array\n    to avoid caching.\n\n    When reading data in sleeplab format, use `values` since the `values_func`\n    returned by the reader should return `np.memmap` instead of the full array.\n    \"\"\"\n    attributes: ArrayAttributes\n    values_func: Callable[[], np.ndarray]\n\n    @cached_property\n    def values(self) -&gt; np.ndarray | zarr.Array:\n        \"\"\"Use @cached_property so that values_func gets evaluated once\n        when values is accessed first time.\n        \"\"\"\n        return self.values_func()\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.SampleArray.values","title":"<code>values: np.ndarray | zarr.Array</code>  <code>cached</code> <code>property</code>","text":"<p>Use @cached_property so that values_func gets evaluated once when values is accessed first time.</p>"},{"location":"api/models/#sleeplab_format.models.ArrayAttributes","title":"<code>ArrayAttributes</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class ArrayAttributes(BaseModel, extra='forbid'):\n    name: str\n    start_ts: NaiveDatetime\n    sampling_rate: Optional[float] = None\n    sampling_interval: Optional[float] = None\n    unit: Optional[str] = None\n\n    amplifier_info: Optional[str] = None\n    sensor_info: Optional[str] = None\n\n    # An optional mapping from the array values to some other values,\n    # e.g.  {0: 'off', 1: 'on'}\n    value_map: Optional[dict[int, str | int]] = None\n\n    @model_validator(mode='after')\n    def require_rate_or_interval(self):\n        if self.sampling_interval is None:\n            _msg = 'either sampling_rate or sampling_interval needs to be defined'\n            assert self.sampling_rate is not None, _msg\n        else:\n            _msg = 'cannot define both sampling_rate and sampling_interval'\n            assert self.sampling_rate is None, _msg\n\n        return self\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.BaseAnnotations","title":"<code>BaseAnnotations</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class BaseAnnotations(BaseModel):\n    scorer: str\n    type: str\n    annotations: list[Annotation]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Annotations","title":"<code>Annotations</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Annotations(BaseAnnotations):\n    type: Literal['annotations'] = 'annotations'\n    annotations: list[Annotation[str]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMEvents","title":"<code>AASMEvents</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMEvents(BaseAnnotations):\n    type: Literal['aasmevents'] = 'aasmevents'\n    annotations: list[Annotation[AASMEvent]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Hypnogram","title":"<code>Hypnogram</code>","text":"<p>             Bases: <code>BaseAnnotations</code></p> <p>A hypnogram is Annotations consisting of sleep stages.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Hypnogram(BaseAnnotations):\n    \"\"\"A hypnogram is Annotations consisting of sleep stages.\"\"\"\n    type: Literal['hypnogram'] = 'hypnogram'\n    annotations: list[Annotation[AASMSleepStage]]\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.Sex","title":"<code>Sex</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class Sex(str, Enum):\n    FEMALE = 'FEMALE'\n    MALE = 'MALE'\n    OTHER = 'OTHER'\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMEvent","title":"<code>AASMEvent</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for events scored according to the AASM manual v2.6.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMEvent(str, Enum):\n    \"\"\"Enum for events scored according to the AASM manual v2.6.\"\"\"\n    # A generic class for artifacts\n    ARTIFACT = 'ARTIFACT'\n\n    # A generic class for unsure\n    UNSURE = 'UNSURE'\n\n    # Arousal events\n    AROUSAL = 'AROUSAL'\n    AROUSAL_RES = 'AROUSAL_RES'\n    AROUSAL_SPONT = 'AROUSAL_SPONT'\n    AROUSAL_LM = 'AROUSAL_LM'\n    AROUSAL_PLM = 'AROUSAL_PLM'\n    RERA = 'RERA'\n\n    # Cardiac events\n    # TODO: Add these if a use case ever pops up\n\n    # Movement events\n    BRUXISM = 'BRUXISM'\n    LM = 'LM'  # Leg movement\n    LM_LEFT = 'LM_LEFT',\n    LM_RIGHT = 'LM_RIGHT',\n    PLM = 'PLM'  # Periodic leg movement\n    PLM_LEFT = 'PLM_LEFT'\n    PLM_RIGHT = 'PLM_RIGHT'\n\n    # Respiratory events\n    APNEA = 'APNEA'\n    APNEA_CENTRAL = 'APNEA_CENTRAL'\n    APNEA_OBSTRUCTIVE = 'APNEA_OBSTRUCTIVE'\n    APNEA_MIXED = 'APNEA_MIXED'\n    HYPOPNEA = 'HYPOPNEA'\n    HYPOPNEA_CENTRAL = 'HYPOPNEA_CENTRAL'\n    HYPOPNEA_OBSTRUCTIVE = 'HYPOPNEA_OBSTRUCTIVE'\n    SPO2_DESAT = 'SPO2_DESAT'\n    SNORE = 'SNORE'\n</code></pre>"},{"location":"api/models/#sleeplab_format.models.AASMSleepStage","title":"<code>AASMSleepStage</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Sleep stages according to the AASM manual v2.6.</p> Source code in <code>src/sleeplab_format/models.py</code> <pre><code>class AASMSleepStage(str, Enum):\n    \"\"\"Sleep stages according to the AASM manual v2.6.\"\"\"\n    W = 'W'\n    N1 = 'N1'\n    N2 = 'N2'\n    N3 = 'N3'\n    R = 'R'\n\n    # These are not part of the AASM v2.6 definition, but still commonly used\n    UNSURE = 'UNSURE'\n    UNSCORED = 'UNSCORED'\n    ARTIFACT = 'ARTIFACT'\n</code></pre>"},{"location":"api/reader/","title":"Reader","text":"<p>Read files into sleeplab format. The data will be validated while parsing.</p>"},{"location":"api/reader/#sleeplab_format.reader.read_dataset","title":"<code>read_dataset(ds_dir, series_names=None, include_annotations=True)</code>","text":"<p>Read a dataset stored in sleeplab-format.</p> <p>Parameters:</p> Name Type Description Default <code>ds_dir</code> <code>Path</code> <p>The dataset root folder.</p> required <code>series_names</code> <code>list[str] | None</code> <p>The series included in the resulting dataset.</p> <code>None</code> <code>include_annotations</code> <code>bool</code> <p>Whether to include annotations or only read the sample arrays.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The resulting dataset.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_dataset(\n        ds_dir: Path,\n        series_names: list[str] | None = None,\n        include_annotations: bool = True) -&gt; Dataset:\n    \"\"\"Read a dataset stored in sleeplab-format.\n\n    Arguments:\n        ds_dir: The dataset root folder.\n        series_names: The series included in the resulting dataset.\n        include_annotations: Whether to include annotations or only read the sample arrays.\n\n    Returns:\n        The resulting dataset.\n    \"\"\"\n    with open(ds_dir / 'metadata.json', 'r') as f:\n        ds_meta = json.load(f)\n\n    assert ds_meta['name'] == ds_dir.name\n    if ds_meta['version'] != SLEEPLAB_FORMAT_VERSION:\n        logger.warning(\n            f'Reading dataset version {ds_meta[\"version\"]} with sleeplab-format version {SLEEPLAB_FORMAT_VERSION}')\n\n    if series_names is None:\n        series = {series_dir.name: read_series(\n                series_dir, include_annotations=include_annotations)\n            for series_dir in ds_dir.iterdir()\n            if series_dir.is_dir() and not series_dir.name.startswith('.')}  # Ignore hidden folders.\n    else:\n        series = {series_name: read_series(\n                ds_dir / series_name, include_annotations=include_annotations)\n            for series_name in series_names}\n\n    return Dataset(\n        series=series,\n        **ds_meta\n    )\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_series","title":"<code>read_series(series_dir, include_annotations=True)</code>","text":"<p>Read a single series to <code>sleeplab_format.models.Series</code>.</p> <p>Parameters:</p> Name Type Description Default <code>series_dir</code> <code>Path</code> <p>The series root folder.</p> required <code>include_annotations</code> <code>bool</code> <p>Whether to include the annotations.</p> <code>True</code> <p>Returns:</p> Type Description <code>Series</code> <p>The resulting series.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_series(\n        series_dir: Path,\n        include_annotations: bool = True) -&gt; Series:\n    \"\"\"Read a single series to `sleeplab_format.models.Series`.\n\n    Arguments:\n        series_dir: The series root folder.\n        include_annotations: Whether to include the annotations.\n\n    Returns:\n        The resulting series.\n    \"\"\"\n    return Series(\n        name=series_dir.name,\n        subjects={subject_dir.name: read_subject(\n                subject_dir, include_annotations=include_annotations)\n            for subject_dir in series_dir.iterdir()\n            if not subject_dir.name.startswith('.')}  # Ignore hidden folders.\n    )\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_annotations","title":"<code>read_annotations(subject_dir)</code>","text":"<p>Read all subject's annotations.</p> <p>Parameters:</p> Name Type Description Default <code>subject_dir</code> <code>Path</code> <p>The subject folder.</p> required <p>Returns:</p> Type Description <code>dict[str, list[Annotation]] | None</code> <p>All annotations in a dictionary.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_annotations(subject_dir: Path) -&gt; dict[str, list[Annotation]] | None:\n    \"\"\"Read all subject's annotations.\n\n    Arguments:\n        subject_dir: The subject folder.\n\n    Returns:\n        All annotations in a dictionary.\n    \"\"\"\n    annotations = {}\n    for p in subject_dir.iterdir():\n\n        if p.name.endswith(JSON_ANNOTATION_SUFFIX):            \n            annotation_name = p.name.removesuffix(JSON_ANNOTATION_SUFFIX)\n            with open(p, 'rb') as f:\n                raw_data = f.read()\n                annotations[annotation_name] = BaseAnnotations.model_validate_json(raw_data)\n        elif p.name.endswith(PARQUET_ANNOTATION_SUFFIX):\n            annotation_name = p.name.removesuffix(PARQUET_ANNOTATION_SUFFIX)\n            annotation_meta_path = subject_dir / f'{annotation_name}{PARQUET_ANNOTATION_META_SUFFIX}'\n\n            with open(annotation_meta_path, 'r') as f:\n                ann_dict = json.load(f)\n\n            ann_df = pd.read_parquet(p)\n            ann_dict['annotations'] = ann_df.to_dict('records')\n\n            annotations[annotation_name] = BaseAnnotations.model_validate(ann_dict)\n\n    if len(annotations) == 0:\n        return None\n    return annotations\n</code></pre>"},{"location":"api/reader/#sleeplab_format.reader.read_sample_arrays","title":"<code>read_sample_arrays(subject_dir)</code>","text":"<p>Read all subject's sample arrays.</p> <p>Parameters:</p> Name Type Description Default <code>subject_dir</code> <code>Path</code> <p>The subject folder.</p> required <p>Returns:</p> Type Description <code>dict[str, SampleArray] | None</code> <p>All sample arrays in a dictionary.</p> Source code in <code>src/sleeplab_format/reader.py</code> <pre><code>def read_sample_arrays(subject_dir: Path) -&gt; dict[str, SampleArray] | None:\n    \"\"\"Read all subject's sample arrays.\n\n    Arguments:\n        subject_dir: The subject folder.\n\n    Returns:\n        All sample arrays in a dictionary.\n    \"\"\"\n    sarrs = {}\n    for p in subject_dir.iterdir():\n        if p.is_dir() and not p.name.startswith('.'):\n            with open(p / 'attributes.json', 'rb') as f:\n                raw_data = f.read()\n                attributes = ArrayAttributes.model_validate_json(raw_data)\n\n            if (p / 'data.npy').exists():\n                # Return a function that returns a memmapped numpy array\n                values_func = lambda _p=p / 'data.npy': np.load(\n                    _p, mmap_mode='r', allow_pickle=False)\n            elif (p / 'data.parquet').exists():\n                values_func = lambda _p=p / 'data.parquet': pq.read_table(\n                    _p)['data'].to_numpy()\n            elif (p / 'data.zarr').exists():\n                values_func = lambda _p=p / 'data.zarr': zarr.open(_p, mode='r')\n            else:\n                raise FileNotFoundError(f'No data.npy or data.parquet in {p}')\n\n            assert p.name == attributes.name\n            sarrs[p.name] = SampleArray(\n                attributes=attributes, values_func=values_func)\n    return sarrs\n</code></pre>"},{"location":"api/writer/","title":"Writer","text":"<p>Write validated data into sleeplab format.</p> <p>The data needs to conform to the types specified in <code>sleeplab_format.models</code>.</p>"},{"location":"api/writer/#sleeplab_format.writer.write_dataset","title":"<code>write_dataset(dataset, basedir, annotation_format='json', array_format='numpy', compression_level=9)</code>","text":"<p>Write a SLF dataset to disk.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>A sleeplab_format.models.Dataset.</p> required <code>basedir</code> <code>str</code> <p>The folder where the dataset will be saved.</p> required <code>annotation_format</code> <code>str</code> <p>The format of the annotation files.</p> <code>'json'</code> <code>array_format</code> <code>str</code> <p>The format of the sample array data files.</p> <code>'numpy'</code> <code>compression_level</code> <code>int</code> <p>The zstd compression level if <code>array_format</code> is <code>zarr</code>.</p> <code>9</code> Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_dataset(\n        dataset: Dataset,\n        basedir: str,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy',\n        compression_level: int = 9) -&gt; None:\n    \"\"\"Write a SLF dataset to disk.\n\n    Arguments:\n        dataset: A sleeplab_format.models.Dataset.\n        basedir: The folder where the dataset will be saved.\n        annotation_format: The format of the annotation files.\n        array_format: The format of the sample array data files.\n        compression_level: The zstd compression level if `array_format` is `zarr`.\n    \"\"\"\n    assert annotation_format in ['json', 'parquet']\n    assert array_format in ['numpy', 'parquet', 'zarr']\n\n    # Create the folder\n    dataset_path = Path(basedir) / dataset.name\n    logger.info(f'Creating dataset dir {dataset_path}...')\n    dataset_path.mkdir(parents=True, exist_ok=True)\n\n    # Write the dataset metadata\n    metadata_path = dataset_path / 'metadata.json'\n    metadata_path.write_text(\n        dataset.model_dump_json(exclude={'series'}, indent=JSON_INDENT))\n\n    # Write the series\n    for name, series in dataset.series.items():\n        assert name == series.name\n        logger.info(f'Writing data for series {series.name}...')\n        series_path = dataset_path / series.name\n        series_path.mkdir(exist_ok=True)\n\n        write_series(\n            series,\n            series_path,\n            annotation_format=annotation_format,\n            array_format=array_format,\n            compression_level=compression_level)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_series","title":"<code>write_series(series, series_path, annotation_format='json', array_format='numpy', compression_level=9)</code>","text":"<p>Write a sleeplab_format.models.Series to disk.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The sleeplab_format.models.Series to save.</p> required <code>series_path</code> <code>Path</code> <p>The path to the folder where the series will be saved.</p> required <code>annotation_format</code> <code>str</code> <p>The format of the annotation files.</p> <code>'json'</code> <code>array_format</code> <code>str</code> <p>The format of the sample array data files.</p> <code>'numpy'</code> <code>compression_level</code> <code>int</code> <p>The zstd compression level if <code>array_format</code> is <code>zarr</code>.</p> <code>9</code> Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_series(\n        series: Series,\n        series_path: Path,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy',\n        compression_level: int = 9) -&gt; None:\n    \"\"\"Write a sleeplab_format.models.Series to disk.\n\n    Arguments:\n        series: The sleeplab_format.models.Series to save.\n        series_path: The path to the folder where the series will be saved.\n        annotation_format: The format of the annotation files.\n        array_format: The format of the sample array data files.\n        compression_level: The zstd compression level if `array_format` is `zarr`.\n    \"\"\"\n    for sid, subject in series.subjects.items():\n        logger.info(f'Writing subject ID {sid}...')\n        subject_path = series_path / subject.metadata.subject_id\n        write_subject(\n            subject,\n            subject_path,\n            annotation_format=annotation_format,\n            array_format=array_format,\n            compression_level=compression_level)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_subject","title":"<code>write_subject(subject, subject_path, annotation_format='json', array_format='numpy', compression_level=9)</code>","text":"<p>Write a single Subject to disk.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>Subject</code> <p>A sleeplab_format.models.Subject to save.</p> required <code>subject_path</code> <code>Path</code> <p>Path to the subject save folder.</p> required <code>annotation_format</code> <code>str</code> <p>The format of annotation files.</p> <code>'json'</code> <code>array_format</code> <code>str</code> <p>The format of the sample array data files.</p> <code>'numpy'</code> <code>compression_level</code> <code>int</code> <p>The zstd compression level if <code>array_format</code> is <code>zarr</code>.</p> <code>9</code> Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_subject(\n        subject: Subject,\n        subject_path: Path,\n        annotation_format: str = 'json',\n        array_format: str = 'numpy',\n        compression_level: int = 9) -&gt; None:\n    \"\"\"Write a single Subject to disk.\n\n    Arguments:\n        subject: A sleeplab_format.models.Subject to save.\n        subject_path: Path to the subject save folder.\n        annotation_format: The format of annotation files.\n        array_format: The format of the sample array data files.\n        compression_level: The zstd compression level if `array_format` is `zarr`.\n    \"\"\"\n    subject_path.mkdir(exist_ok=True)\n    write_subject_metadata(subject, subject_path)\n\n    write_sample_arrays(subject, subject_path, format=array_format,\n                        zarr_compression_level=compression_level)\n\n    if subject.annotations is not None:\n        write_annotations(subject, subject_path, format=annotation_format)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_annotations","title":"<code>write_annotations(subject, subject_path, format='json')</code>","text":"<p>Write SLF annotations to disk.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>Subject</code> <p>A sleeplab_format.models.Subject whose annotations will be written.</p> required <code>subject_path</code> <code>Path</code> <p>The path to the subject folder.</p> required <code>format</code> <code>str</code> <p>The format of annotation files.</p> <code>'json'</code> Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_annotations(\n        subject: Subject,\n        subject_path: Path,\n        format: str = 'json') -&gt; None:\n    \"\"\"Write SLF annotations to disk.\n\n    Arguments:\n        subject: A sleeplab_format.models.Subject whose annotations will be written.\n        subject_path: The path to the subject folder.\n        format: The format of annotation files.\n    \"\"\"\n    for k, v in subject.annotations.items():\n        _msg = f'Annotation key should equal to \"{v.scorer}_{v.type}\", got \"{k}\"'\n        assert k == f'{v.scorer}_{v.type}', _msg\n\n        if format == 'json':\n            json_path = subject_path / f'{k}{JSON_ANNOTATION_SUFFIX}'\n            json_path.write_text(\n                v.model_dump_json(exclude_none=True, indent=JSON_INDENT)\n            )\n        else:\n            # Write the actual annotations in parquet, metadata in json\n            metadata_path = subject_path / f'{k}{PARQUET_ANNOTATION_META_SUFFIX}'\n            pq_path = subject_path / f'{k}{PARQUET_ANNOTATION_SUFFIX}'\n\n            ann_dict = v.model_dump()\n            ann_list = ann_dict.pop('annotations')\n\n            with open(metadata_path, 'w') as f:\n                json.dump(ann_dict, f)\n\n            pd.DataFrame(ann_list).to_parquet(pq_path)\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_sample_arrays","title":"<code>write_sample_arrays(subject, subject_path, format='numpy', zarr_chunksize=5000000.0, zarr_compression_level=9)</code>","text":"<p>Write all sample arrays of the subject.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>Subject</code> <p>The sleeplab.models.Subject instance.</p> required <code>subject_path</code> <code>Path</code> <p>Path to the folder where the sample arrays are saved.</p> required <code>format</code> <code>str</code> <p>The save format for the numerical arrays; <code>numpy</code>, <code>parquet</code> or <code>zarr</code>.</p> <code>'numpy'</code> <code>zarr_chunksize</code> <code>int | None</code> <p>The chunk size in bytes if <code>format='zarr'</code>.</p> <code>5000000.0</code> <code>zarr_compression_level</code> <code>int</code> <p>The compression level used with the Zstandard compression.</p> <code>9</code> Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_sample_arrays(\n        subject: Subject,\n        subject_path: Path,\n        format: str = 'numpy',\n        zarr_chunksize: int | None = 5e6,\n        zarr_compression_level: int = 9) -&gt; None:\n    \"\"\"Write all sample arrays of the subject.\n\n    Arguments:\n        subject: The sleeplab.models.Subject instance.\n        subject_path: Path to the folder where the sample arrays are saved.\n        format: The save format for the numerical arrays; `numpy`, `parquet` or `zarr`.\n        zarr_chunksize: The chunk size in bytes if `format='zarr'`.\n        zarr_compression_level: The compression level used with the Zstandard compression.\n    \"\"\"\n    for name, sarr in subject.sample_arrays.items():\n        assert name == sarr.attributes.name\n        sarr_path = subject_path / f'{sarr.attributes.name}'\n        sarr_path.mkdir(exist_ok=True)\n\n        # Write the attributes\n        attr_path = sarr_path / 'attributes.json'\n        attr_path.write_text(\n            sarr.attributes.model_dump_json(indent=JSON_INDENT, exclude_none=True))\n\n        arr = sarr.values_func()\n        if format == 'numpy':\n            # Write the array\n            arr_fname = 'data.npy'\n            np.save(sarr_path / arr_fname, arr, allow_pickle=False)\n        elif format == 'zarr':\n            arr_fname = 'data.zarr'\n            #shuffler = numcodecs.Shuffle(elementsize=4)\n            #delta = numcodecs.Delta(dtype='i2')\n            #compressor = numcodecs.Blosc(cname='zstd', clevel=5, shuffle=numcodecs.Blosc.NOSHUFFLE)\n            #compressor = numcodecs.Blosc(cname='zstd', clevel=9, shuffle=numcodecs.Blosc.NOSHUFFLE)\n            #compressor = numcodecs.Blosc(cname='lz4', clevel=5, shuffle=numcodecs.Blosc.NOSHUFFLE)\n            #compressor = numcodecs.ZFPY(mode=4, tolerance=1e-3)\n            #zarr.save_array(sarr_path / arr_fname, arr, filters=[shuffler, delta], compressor=compressor)\n            if zarr_chunksize is not None:\n                # Chunk size from bytes to samples\n                chunks = (zarr_chunksize // arr.dtype.itemsize,)\n                z = zarr.array(arr, chunks=chunks)\n\n            #compressor = numcodecs.Blosc(cname='zstd', clevel=zarr_compression_level, shuffle=numcodecs.Blosc.NOSHUFFLE)\n            compressor = numcodecs.Zstd(level=zarr_compression_level)\n            zarr.save_array(sarr_path / arr_fname, z, compressor=compressor)\n        elif format == 'parquet':\n            arr_fname = 'data.parquet'\n\n            # Utilize Arrow to write the data to Parquet file\n            arrow_table = pa.Table.from_arrays([arr], names=['data'])\n\n            # Parquet uses Snappy as compression algorithm by default\n            pq.write_table(arrow_table, sarr_path / arr_fname)\n        else:\n            raise AttributeError(f'Unsupported sample array format: {format}')\n</code></pre>"},{"location":"api/writer/#sleeplab_format.writer.write_subject_metadata","title":"<code>write_subject_metadata(subject, subject_path)</code>","text":"<p>Write subject metadata to JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>Subject</code> <p>The sleeplab_format.models.Subject whose metadata will be saved.</p> required <code>subject_path</code> <code>Path</code> <p>The path to the subject folder.</p> required Source code in <code>src/sleeplab_format/writer.py</code> <pre><code>def write_subject_metadata(\n        subject: Subject,\n        subject_path: Path) -&gt; None:\n    \"\"\"Write subject metadata to JSON file.\n\n    Arguments:\n        subject: The sleeplab_format.models.Subject whose metadata will be saved.\n        subject_path: The path to the subject folder.\n    \"\"\"\n    metadata_path = subject_path / 'metadata.json'\n    metadata_path.write_text(\n        subject.metadata.model_dump_json(indent=JSON_INDENT, exclude_none=True),\n    )\n</code></pre>"},{"location":"examples/automatic_sleep_staging/","title":"Sleep staging using Dreem Open Datasets","text":"<p>This is an end-to-end example of how to convert data from another format to sleeplab format, how to preprocess the data using sleeplab-extractor, and how to train a deep learning model utilizing sleeplab-tf-dataset. The code is available on Github. This example uses data from Dreem Open Datasets (DOD) since the DOD is well documented and open access (https://doi.org/10.1109/TNSRE.2020.3011181).</p>"},{"location":"examples/automatic_sleep_staging/#prerequisites","title":"Prerequisites","text":"<p>The code is developed and tested with Linux and Python 3.10. Windows users can install Windows Subsystem for Linux to run this example (and to use Linux for development in general).</p> <p>If you do not yet have a copy of this example, you can clone the repository to current working directory and go to the example folder: <pre><code>git clone https://github.com/UEF-SmartSleepLab/sleeplab-format.git\ncd sleeplab-format/examples/dod_sleep_staging\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#install-dependencies","title":"Install dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"examples/automatic_sleep_staging/#convert-data-to-sleeplab-format","title":"Convert data to sleeplab format","text":"<p>NOTE: This will download and convert the whole dataset with the original 250Hz sampling rate. The h5 files take 57 GB on disk, and the converted slf dataset takes 30 GB.</p> <p>The examples below use <code>/tmp</code> as the base directory. Substitute it with another location if you want to persist the data and results.</p> <p>First, download the datasets <pre><code>mkdir /tmp/dod\npython download_data.py --dst-dir /tmp/dod\n</code></pre></p> <p>Then, run the conversion <pre><code>python convert_data.py --src-dir /tmp/dod --dst-dir /tmp/slf\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#extract-and-preprocess-a-subset-of-the-signals","title":"Extract and preprocess a subset of the signals","text":"<p>Use sleeplab-extractor to extract a single EEG channel, EOG channel, and EMG channel. Resample to 64Hz, highpass filter, and normalize the signals.</p> <p>All configurations for the extractor are in <code>sleeplab_extractor_config.yml</code>.</p> <p>To perform the extraction, run in this directory: <pre><code>sleeplab-extract --src_dir /tmp/slf/dod --dst_dir /tmp/slf --config_path ./sleeplab_extractor_config.yml\n</code></pre></p>"},{"location":"examples/automatic_sleep_staging/#train-a-sleep-staging-model-with-the-data","title":"Train a sleep staging model with the data","text":"<p>Now, use the preprocessed 64Hz data for automatic sleep staging. The model and training loop are defined in <code>train.py</code>.</p> <pre><code>python train.py --model-dir /tmp/dod_models --epochs 100\n</code></pre> <p>This should achieve 75-85% validation accuracy, and 70-80% test accuracy. Since the dataset is relatively small (50, 11, and 20 recordings for training, validation, and test sets), the performance fluctuates quite much between the runs. No hyperparameter tuning has been performed, default values are used everywhere.</p>"},{"location":"examples/edf_conversion/","title":"Converting the Sleep Cassette dataset to sleeplab-format","text":"<p>This is an example of how to convert EDF and EDF+ files to sleeplab-format. The example uses the Sleep Cassette dataset, which is openly available for download and usage.</p>"},{"location":"examples/edf_conversion/#setup","title":"Setup","text":"<p>Clone the sleeplab-format repo and <code>cd</code> to the example folder. <pre><code>git clone https://github.com/UEF-SmartSleepLab/sleeplab-format.git\ncd examples/sleep_edf_conversion\n</code></pre></p> <p>Create environment with Python 3.10, for example with conda: <pre><code>conda create -n sleep_edf_conversion python=3.10\nconda activate sleep_edf_conversion\n</code></pre></p> <p>Install requirements <pre><code>pip install -r requirements.txt\n</code></pre></p>"},{"location":"examples/edf_conversion/#download-the-data","title":"Download the data","text":"<pre><code>wget -r -N -c -np https://physionet.org/files/sleep-edfx/1.0.0/\n</code></pre>"},{"location":"examples/edf_conversion/#convert-to-sleeplab-format","title":"Convert to sleeplab-format","text":"<p>The code for conversion is in <code>convert_data.py</code>. The module provides a command line interface, which takes as arguments: - --src-dir: The folder containing the original EDF data (<code>SC-subjects.xls</code> Excel and <code>sleep-cassette/</code> folder). - --dst-dir: The folder where the sleeplab-format dataset will be saved. - --array-format: The save format of the signals; <code>numpy</code> or <code>parquet</code>. - --annotation-format: The save format of the annotation files; <code>json</code> or <code>parquet</code>.</p> <p>For example, to store the signals as parquet files, and annotations as json files: <pre><code>python convert_data.py --src-dir physionet.org/files/sleep-edfx/1.0.0 \\\n    --dst-dir /tmp/sleeplab_format --array-format parquet --annotation-format json\n</code></pre></p> <p>The Sleep-Cassette dataset contains 153 PSG recordings, 20h duration each. There are two recordings recorded on consecutive dates for each subject. Detailed information can be found on the dataset documentation. The consecutive recordings are stored in separate sleeplab-format series <code>sc-night1</code> and <code>sc-night2</code>. Detailed information on the sleeplab-format data structures can be found in the sleeplab-format documentation.</p>"},{"location":"examples/edf_conversion/#resulting-dataset-sizes","title":"Resulting dataset sizes","text":"Dataset Size (Gb) Original EDF files 7.42 SLF, array format <code>numpy</code> 14.85 SLF, array format <code>parquet</code> 5.36 <p>The EDF files stores signals as 16-bit signed ints. In this example, the signals are stored as 32-bit floats in the sleeplab-format, which doubles the dataset size if uncompressed numpy files are used for the signals. However, if the signals are saved in parquet files, the size is reduced significantly from the original EDF files. The reason for this size reduction is currently not known. Parquet uses Snappy compression algorithm, which encodes recurring patterns as (pattern, count) pairs. However, EEG, EOG, and EMG signals are characterized by random fluctuations and noise, which means that a lossless compression algorithm should not be able to compress the data significantly. The size reduction might be related to the AD and EDF conversions, signal filtering, and artefacts.</p>"}]}